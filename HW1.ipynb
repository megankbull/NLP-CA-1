{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     /Users/meganbull/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package omw-1.4 to\n",
      "[nltk_data]     /Users/meganbull/nltk_data...\n",
      "[nltk_data]   Package omw-1.4 is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to /Users/meganbull/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import nltk\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "from nltk.tokenize import word_tokenize # added\n",
    "\n",
    "nltk.download('wordnet') # added\n",
    "nltk.download('omw-1.4') # added\n",
    "nltk.download('punkt') # added\n",
    "\n",
    "import re\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import Perceptron, LogisticRegression\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn import metrics\n",
    "\n",
    "# sklearn has preprocessing \n",
    "# can convert strinbg labels into numbers\n",
    "\n",
    "import contractions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ! python3 -m pip install bs4 # in case you don't have it installed\n",
    "\n",
    "# Dataset: https://s3.amazonaws.com/amazon-reviews-pds/tsv/amazon_reviews_us_Jewelry_v1_00.tsv.gz\n",
    "\n",
    "f_path = 'amazon_reviews_us_Jewelry_v1_00.tsv'\n",
    "\n",
    "STAR_H = 'star_rating'\n",
    "REVIEW_H = 'review_body'\n",
    "\n",
    "cols=[STAR_H, REVIEW_H]\n",
    "\n",
    "valid_ratings = {'1', '2', '3', '4', '5'}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape before dropping NaN vals: (1767051, 2)\n",
      "Shape after dropping NaN vals: (1766807, 2)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>star_rating</th>\n",
       "      <th>review_body</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5</td>\n",
       "      <td>so beautiful even tho clearly not high end ......</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5</td>\n",
       "      <td>Great product.. I got this set for my mother, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>Exactly as pictured and my daughter's friend l...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5</td>\n",
       "      <td>Love it. Fits great. Super comfortable and nea...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Got this as a Mother's Day gift for my Mom and...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  star_rating                                        review_body\n",
       "0           5  so beautiful even tho clearly not high end ......\n",
       "1           5  Great product.. I got this set for my mother, ...\n",
       "2           5  Exactly as pictured and my daughter's friend l...\n",
       "3           5  Love it. Fits great. Super comfortable and nea...\n",
       "4           5  Got this as a Mother's Day gift for my Mom and..."
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(f_path, sep='\\t', usecols=cols, low_memory=False)\n",
    "print(f\"Shape before dropping NaN vals: {df.shape}\")\n",
    "df.dropna(inplace=True)\n",
    "print(f\"Shape after dropping NaN vals: {df.shape}\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['5', '1', '4', '3', '2'], dtype=object)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[STAR_H].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ## We select 20000 reviews randomly from each rating class.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(100000, 2)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>star_rating</th>\n",
       "      <th>review_body</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>115945</th>\n",
       "      <td>4</td>\n",
       "      <td>Great shade.  I also purchased the long neckla...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1753716</th>\n",
       "      <td>4</td>\n",
       "      <td>These are dainty, lovely earrings...especially...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1300065</th>\n",
       "      <td>4</td>\n",
       "      <td>This is a beautifully delicate amethyst rosary...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1016218</th>\n",
       "      <td>4</td>\n",
       "      <td>I loved the two longer chains. The smallest on...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1518214</th>\n",
       "      <td>4</td>\n",
       "      <td>Awesome product would order again as well as t...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        star_rating                                        review_body\n",
       "115945            4  Great shade.  I also purchased the long neckla...\n",
       "1753716           4  These are dainty, lovely earrings...especially...\n",
       "1300065           4  This is a beautifully delicate amethyst rosary...\n",
       "1016218           4  I loved the two longer chains. The smallest on...\n",
       "1518214           4  Awesome product would order again as well as t..."
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s_size = 20000\n",
    "\n",
    "grouped = df.groupby(STAR_H)\n",
    "rat_dfs = [grouped.get_group(rating).sample(n=s_size) for rating in valid_ratings]\n",
    "\n",
    "sampled = pd.concat(rat_dfs)\n",
    "# sampled[STAR_H] = sampled[STAR_H].astype(\"category\")\n",
    "print(sampled.shape)\n",
    "sampled.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Cleaning\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- convert the all reviews into the lower case. (**DONE**)\n",
    "- remove the HTML and URLs from the reviews (**DONE**)\n",
    "- remove non-alphabetical characters (**DONE**)\n",
    "- remove extra spaces (**DONE**)\n",
    "- perform contractions on the reviews, e.g., wonâ€™t -> will not (**DONE**)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average character length pre-clean: 190.29024\n"
     ]
    }
   ],
   "source": [
    "raw_len_avg = sampled[REVIEW_H].str.len().mean()\n",
    "\n",
    "print(f'Average character length pre-clean: {raw_len_avg}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/site-packages/bs4/__init__.py:435: MarkupResemblesLocatorWarning: The input looks more like a filename than markup. You may want to open this file and pass the filehandle into Beautiful Soup.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "def gen_clean(text):\n",
    "    \"\"\"\n",
    "    gen text cleanup \n",
    "    incl removal: extended ws, html tags, urls\n",
    "    \"\"\"\n",
    "    text = BeautifulSoup(text, \"html.parser\").text #rm html tags \n",
    "    text = re.sub(r'http\\S+', r'', text)\n",
    "    text = contractions.fix(text)\n",
    "\n",
    "    for c in text: \n",
    "        if not c.isalpha():\n",
    "            text = text.replace(c, ' ')\n",
    "\n",
    "    text = re.sub(\" +\", \" \", text)\n",
    "    \n",
    "    return text.lower()\n",
    "\n",
    "sampled[REVIEW_H] = sampled[REVIEW_H].apply(gen_clean)\n",
    "sampled.sort_index(inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average character length post-clean: 184.19912\n"
     ]
    }
   ],
   "source": [
    "cl_len_avg = sampled[REVIEW_H].str.len().mean()\n",
    "\n",
    "print(f'Average character length post-clean: {cl_len_avg}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pre-processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## remove the stop words "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rm_stops(text): \n",
    "   \"\"\"\n",
    "   remove stop words from text \n",
    "   \"\"\"\n",
    "   stops = set(stopwords.words(\"english\"))\n",
    "   sans_stops = [tok for tok in word_tokenize(text) if tok not in stops]\n",
    "   return \" \".join(sans_stops).strip()\n",
    "\n",
    "sampled[REVIEW_H] = sampled[REVIEW_H].apply(rm_stops)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## perform lemmatization  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "wnl = WordNetLemmatizer()\n",
    "\n",
    "def lemmatize(text): \n",
    "   lemmas = [wnl.lemmatize(w) for w in word_tokenize(text)]\n",
    "   return \" \".join(lemmas)\n",
    "   \n",
    "sampled[REVIEW_H] = sampled[REVIEW_H].apply(lemmatize)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average character length after preproc: 108.34514\n"
     ]
    }
   ],
   "source": [
    "preproc_len_avg = sampled[REVIEW_H].str.len().mean()\n",
    "\n",
    "print(f'Average character length after preproc: {preproc_len_avg}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TF-IDF Feature Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "v = TfidfVectorizer()\n",
    "feat = v.fit_transform(sampled[REVIEW_H]).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data, test_data, train_labels, test_labels = train_test_split(feat, sampled[STAR_H], test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_report(test_labels, test_pred):\n",
    "   classific_dict = classification_report(test_labels, test_pred, output_dict=True)\n",
    "\n",
    "   for k,v in classific_dict.items(): \n",
    "      if k in valid_ratings:\n",
    "         print(f\"Rating {k}:\")\n",
    "         print(f\"\\tPrecision: {v['precision']:.3f}\")\n",
    "         print(f\"\\tRecall: {v['recall']:.3f}\")\n",
    "         print(f\"\\tF1-score: {v['f1-score']:.3f}\")\n",
    "      elif k == 'macro avg':\n",
    "         print(\"Overall Average:\")\n",
    "         print(f\"\\tPrecision: {v['precision']:.3f}\")\n",
    "         print(f\"\\tRecall: {v['recall']:.3f}\")\n",
    "         print(f\"\\tF1-score: {v['f1-score']:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Perceptron"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = Perceptron(random_state=42, max_iter=2000, n_iter_no_change=5) \n",
    "# , early_stopping=True, validation_fraction=0.1, n_iter_no_change=5)\n",
    "# p = Perceptron(random_state=42, eta0=0.1)\n",
    "p.fit(train_data, train_labels)\n",
    "p_pred = p.predict(test_data)\n",
    "print_report(test_labels, p_pred)\n",
    "print(f\"Accuracy: {metrics.accuracy_score(test_labels, p_pred)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svm = LinearSVC()\n",
    "svm.fit(train_data, train_labels)\n",
    "svm_pred = svm.predict(test_data)\n",
    "print_report(test_labels, svm_pred)\n",
    "print(f\"Accuracy: {metrics.accuracy_score(test_labels,svm_pred)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rating 1:\n",
      "\tPrecision: 0.577\n",
      "\tRecall: 0.626\n",
      "\tF1-score: 0.601\n",
      "Rating 2:\n",
      "\tPrecision: 0.415\n",
      "\tRecall: 0.395\n",
      "\tF1-score: 0.405\n",
      "Rating 3:\n",
      "\tPrecision: 0.417\n",
      "\tRecall: 0.402\n",
      "\tF1-score: 0.409\n",
      "Rating 4:\n",
      "\tPrecision: 0.454\n",
      "\tRecall: 0.424\n",
      "\tF1-score: 0.438\n",
      "Rating 5:\n",
      "\tPrecision: 0.642\n",
      "\tRecall: 0.685\n",
      "\tF1-score: 0.663\n",
      "Overall Average:\n",
      "\tPrecision: 0.501\n",
      "\tRecall: 0.506\n",
      "\tF1-score: 0.503\n"
     ]
    }
   ],
   "source": [
    "lr = LogisticRegression(max_iter=200, solver='saga')\n",
    "# lr = LogisticRegression(max_iter=200, solver='sag') \n",
    "# lr = LogisticRegression(max_iter=200, solver='lbfgs') # if using need to incr. max_iters\n",
    "# lr = LogisticRegression(max_iter=200, solver='newton-cg') \n",
    "\n",
    "lr.fit(train_data, train_labels)\n",
    "lr_pred = lr.predict(test_data)\n",
    "print_report(test_labels, lr_pred)\n",
    "print(f\"Accuracy: {metrics.accuracy_score(test_labels, lr_pred)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "A sparse matrix was passed, but dense data is required. Use X.toarray() to convert to a dense numpy array.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/Users/meganbull/Desktop/Fall '22/541-NLP/CAs/CA #1/HW1.ipynb Cell 30\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/meganbull/Desktop/Fall%20%2722/541-NLP/CAs/CA%20%231/HW1.ipynb#X36sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m nb \u001b[39m=\u001b[39m GaussianNB()\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/meganbull/Desktop/Fall%20%2722/541-NLP/CAs/CA%20%231/HW1.ipynb#X36sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m nb\u001b[39m.\u001b[39;49mfit(train_data, train_labels)\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/meganbull/Desktop/Fall%20%2722/541-NLP/CAs/CA%20%231/HW1.ipynb#X36sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m nb_pred \u001b[39m=\u001b[39m nb\u001b[39m.\u001b[39mpredict(test_data)\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/meganbull/Desktop/Fall%20%2722/541-NLP/CAs/CA%20%231/HW1.ipynb#X36sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m print_report(test_labels, nb_pred)\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:243\u001b[0m, in \u001b[0;36mGaussianNB.fit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    220\u001b[0m \u001b[39m\"\"\"Fit Gaussian Naive Bayes according to X, y.\u001b[39;00m\n\u001b[1;32m    221\u001b[0m \n\u001b[1;32m    222\u001b[0m \u001b[39mParameters\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    240\u001b[0m \u001b[39m    Returns the instance itself.\u001b[39;00m\n\u001b[1;32m    241\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    242\u001b[0m y \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_validate_data(y\u001b[39m=\u001b[39my)\n\u001b[0;32m--> 243\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_partial_fit(\n\u001b[1;32m    244\u001b[0m     X, y, np\u001b[39m.\u001b[39;49munique(y), _refit\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m, sample_weight\u001b[39m=\u001b[39;49msample_weight\n\u001b[1;32m    245\u001b[0m )\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:400\u001b[0m, in \u001b[0;36mGaussianNB._partial_fit\u001b[0;34m(self, X, y, classes, _refit, sample_weight)\u001b[0m\n\u001b[1;32m    397\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mclasses_ \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m    399\u001b[0m first_call \u001b[39m=\u001b[39m _check_partial_fit_first_call(\u001b[39mself\u001b[39m, classes)\n\u001b[0;32m--> 400\u001b[0m X, y \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_validate_data(X, y, reset\u001b[39m=\u001b[39;49mfirst_call)\n\u001b[1;32m    401\u001b[0m \u001b[39mif\u001b[39;00m sample_weight \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    402\u001b[0m     sample_weight \u001b[39m=\u001b[39m _check_sample_weight(sample_weight, X)\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/site-packages/sklearn/base.py:596\u001b[0m, in \u001b[0;36mBaseEstimator._validate_data\u001b[0;34m(self, X, y, reset, validate_separately, **check_params)\u001b[0m\n\u001b[1;32m    594\u001b[0m         y \u001b[39m=\u001b[39m check_array(y, input_name\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39my\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mcheck_y_params)\n\u001b[1;32m    595\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 596\u001b[0m         X, y \u001b[39m=\u001b[39m check_X_y(X, y, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mcheck_params)\n\u001b[1;32m    597\u001b[0m     out \u001b[39m=\u001b[39m X, y\n\u001b[1;32m    599\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m no_val_X \u001b[39mand\u001b[39;00m check_params\u001b[39m.\u001b[39mget(\u001b[39m\"\u001b[39m\u001b[39mensure_2d\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mTrue\u001b[39;00m):\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/site-packages/sklearn/utils/validation.py:1074\u001b[0m, in \u001b[0;36mcheck_X_y\u001b[0;34m(X, y, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, multi_output, ensure_min_samples, ensure_min_features, y_numeric, estimator)\u001b[0m\n\u001b[1;32m   1069\u001b[0m         estimator_name \u001b[39m=\u001b[39m _check_estimator_name(estimator)\n\u001b[1;32m   1070\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m   1071\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00mestimator_name\u001b[39m}\u001b[39;00m\u001b[39m requires y to be passed, but the target y is None\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m   1072\u001b[0m     )\n\u001b[0;32m-> 1074\u001b[0m X \u001b[39m=\u001b[39m check_array(\n\u001b[1;32m   1075\u001b[0m     X,\n\u001b[1;32m   1076\u001b[0m     accept_sparse\u001b[39m=\u001b[39;49maccept_sparse,\n\u001b[1;32m   1077\u001b[0m     accept_large_sparse\u001b[39m=\u001b[39;49maccept_large_sparse,\n\u001b[1;32m   1078\u001b[0m     dtype\u001b[39m=\u001b[39;49mdtype,\n\u001b[1;32m   1079\u001b[0m     order\u001b[39m=\u001b[39;49morder,\n\u001b[1;32m   1080\u001b[0m     copy\u001b[39m=\u001b[39;49mcopy,\n\u001b[1;32m   1081\u001b[0m     force_all_finite\u001b[39m=\u001b[39;49mforce_all_finite,\n\u001b[1;32m   1082\u001b[0m     ensure_2d\u001b[39m=\u001b[39;49mensure_2d,\n\u001b[1;32m   1083\u001b[0m     allow_nd\u001b[39m=\u001b[39;49mallow_nd,\n\u001b[1;32m   1084\u001b[0m     ensure_min_samples\u001b[39m=\u001b[39;49mensure_min_samples,\n\u001b[1;32m   1085\u001b[0m     ensure_min_features\u001b[39m=\u001b[39;49mensure_min_features,\n\u001b[1;32m   1086\u001b[0m     estimator\u001b[39m=\u001b[39;49mestimator,\n\u001b[1;32m   1087\u001b[0m     input_name\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mX\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[1;32m   1088\u001b[0m )\n\u001b[1;32m   1090\u001b[0m y \u001b[39m=\u001b[39m _check_y(y, multi_output\u001b[39m=\u001b[39mmulti_output, y_numeric\u001b[39m=\u001b[39my_numeric, estimator\u001b[39m=\u001b[39mestimator)\n\u001b[1;32m   1092\u001b[0m check_consistent_length(X, y)\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/site-packages/sklearn/utils/validation.py:822\u001b[0m, in \u001b[0;36mcheck_array\u001b[0;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator, input_name)\u001b[0m\n\u001b[1;32m    820\u001b[0m \u001b[39mif\u001b[39;00m sp\u001b[39m.\u001b[39missparse(array):\n\u001b[1;32m    821\u001b[0m     _ensure_no_complex_data(array)\n\u001b[0;32m--> 822\u001b[0m     array \u001b[39m=\u001b[39m _ensure_sparse_format(\n\u001b[1;32m    823\u001b[0m         array,\n\u001b[1;32m    824\u001b[0m         accept_sparse\u001b[39m=\u001b[39;49maccept_sparse,\n\u001b[1;32m    825\u001b[0m         dtype\u001b[39m=\u001b[39;49mdtype,\n\u001b[1;32m    826\u001b[0m         copy\u001b[39m=\u001b[39;49mcopy,\n\u001b[1;32m    827\u001b[0m         force_all_finite\u001b[39m=\u001b[39;49mforce_all_finite,\n\u001b[1;32m    828\u001b[0m         accept_large_sparse\u001b[39m=\u001b[39;49maccept_large_sparse,\n\u001b[1;32m    829\u001b[0m         estimator_name\u001b[39m=\u001b[39;49mestimator_name,\n\u001b[1;32m    830\u001b[0m         input_name\u001b[39m=\u001b[39;49minput_name,\n\u001b[1;32m    831\u001b[0m     )\n\u001b[1;32m    832\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    833\u001b[0m     \u001b[39m# If np.array(..) gives ComplexWarning, then we convert the warning\u001b[39;00m\n\u001b[1;32m    834\u001b[0m     \u001b[39m# to an error. This is needed because specifying a non complex\u001b[39;00m\n\u001b[1;32m    835\u001b[0m     \u001b[39m# dtype to the function converts complex to real dtype,\u001b[39;00m\n\u001b[1;32m    836\u001b[0m     \u001b[39m# thereby passing the test made in the lines following the scope\u001b[39;00m\n\u001b[1;32m    837\u001b[0m     \u001b[39m# of warnings context manager.\u001b[39;00m\n\u001b[1;32m    838\u001b[0m     \u001b[39mwith\u001b[39;00m warnings\u001b[39m.\u001b[39mcatch_warnings():\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/site-packages/sklearn/utils/validation.py:512\u001b[0m, in \u001b[0;36m_ensure_sparse_format\u001b[0;34m(spmatrix, accept_sparse, dtype, copy, force_all_finite, accept_large_sparse, estimator_name, input_name)\u001b[0m\n\u001b[1;32m    509\u001b[0m _check_large_sparse(spmatrix, accept_large_sparse)\n\u001b[1;32m    511\u001b[0m \u001b[39mif\u001b[39;00m accept_sparse \u001b[39mis\u001b[39;00m \u001b[39mFalse\u001b[39;00m:\n\u001b[0;32m--> 512\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mTypeError\u001b[39;00m(\n\u001b[1;32m    513\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mA sparse matrix was passed, but dense \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    514\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mdata is required. Use X.toarray() to \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    515\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mconvert to a dense numpy array.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    516\u001b[0m     )\n\u001b[1;32m    517\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39misinstance\u001b[39m(accept_sparse, (\u001b[39mlist\u001b[39m, \u001b[39mtuple\u001b[39m)):\n\u001b[1;32m    518\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(accept_sparse) \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m:\n",
      "\u001b[0;31mTypeError\u001b[0m: A sparse matrix was passed, but dense data is required. Use X.toarray() to convert to a dense numpy array."
     ]
    }
   ],
   "source": [
    "nb = GaussianNB()\n",
    "nb.fit(train_data, train_labels)\n",
    "nb_pred = nb.predict(test_data)\n",
    "print_report(test_labels, nb_pred)\n",
    "print(f\"Accuracy: {metrics.accuracy_score(test_labels, nb_pred)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.6 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "vscode": {
   "interpreter": {
    "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
